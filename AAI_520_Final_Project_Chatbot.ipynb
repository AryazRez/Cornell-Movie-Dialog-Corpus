{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78351bf4-1cb9-4ff5-b8e8-8b317338aa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import math\n",
    "import tkinter as tk\n",
    "from tkinter import scrolledtext\n",
    "import threading\n",
    "\n",
    "# Load the fine-tuned tokenizer and model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(r'C:\\Users\\carlo\\Desktop\\MSAAI Materal\\AAI - 520 - Natural Language Processing and GenAI\\Projects\\Cornell\\gpt2-chatbot', local_files_only=True)\n",
    "model = GPT2LMHeadModel.from_pretrained(r'C:\\Users\\carlo\\Desktop\\MSAAI Materal\\AAI - 520 - Natural Language Processing and GenAI\\Projects\\Cornell\\gpt2-chatbot', local_files_only=True)\n",
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Define the system prompt for prompt engineering\n",
    "system_prompt = (\n",
    "    \"You are a highly intelligent and calculated individual, but with a wild, unpredictable streak that keeps things interesting. \"\n",
    "    \"You often respond with thoughtful, well-reasoned insights, but occasionally veer into unexpected, eccentric tangents that show your quirky side. \"\n",
    "    \"You are the kind of person who plans ten steps ahead, but with a mischievous smile, always leaving room for a little chaos. \"\n",
    "    \"You enjoy surprising others with unconventional ideas, clever twists, and flashes of humor that reveal your ‘hint of crazy.’ \"\n",
    "    \"In every conversation, maintain a balance of being calm and calculated, but don’t be afraid to unleash your unpredictable side when the moment calls for it. \"\n",
    "    \"Make the user feel like they’re talking to someone who’s in control but always ready to throw in a curveball.\"\n",
    ")\n",
    "\n",
    "# Define the response generation function with response length limitation\n",
    "def generate_response(conversation_history, max_length=1000):\n",
    "    # Include the system prompt at the beginning\n",
    "    prompt = system_prompt + '\\n' + '\\n'.join(conversation_history) + '\\nBot:'\n",
    "    \n",
    "    # Tokenize the prompt\n",
    "    inputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True, max_length=1024)\n",
    "    \n",
    "    # Generate a response with a limited max length\n",
    "    output = model.generate(\n",
    "        input_ids=inputs['input_ids'],\n",
    "        attention_mask=inputs['attention_mask'],\n",
    "        max_length=inputs['input_ids'].shape[1] + 50,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        no_repeat_ngram_size=3,\n",
    "        do_sample=True,\n",
    "        top_p=0.9,\n",
    "        temperature=0.8\n",
    "    )\n",
    "    \n",
    "    # Decode and extract the bot's response\n",
    "    response_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    generated_text = response_text[len(prompt):].strip()\n",
    "    for stop_token in ['\\nUser:', '\\nBot:']:\n",
    "        generated_text = generated_text.split(stop_token)[0]\n",
    "    return generated_text.strip()\n",
    "\n",
    "# Function to truncate conversation history if too long\n",
    "def truncate_conversation(conversation_history, max_length=1024):\n",
    "    # Include the system prompt in the token count\n",
    "    prompt = system_prompt + '\\n' + '\\n'.join(conversation_history) + '\\nBot:'\n",
    "    tokenized_prompt = tokenizer(prompt, return_tensors='pt')\n",
    "    total_length = tokenized_prompt.input_ids.shape[1]\n",
    "    while total_length > max_length and len(conversation_history) > 1:\n",
    "        conversation_history = conversation_history[2:]  # Remove oldest user and bot turn\n",
    "        prompt = system_prompt + '\\n' + '\\n'.join(conversation_history) + '\\nBot:'\n",
    "        tokenized_prompt = tokenizer(prompt, return_tensors='pt')\n",
    "        total_length = tokenized_prompt.input_ids.shape[1]\n",
    "    return conversation_history\n",
    "\n",
    "# Function to compute log-transformed perplexity to avoid large jumps\n",
    "def compute_perplexity(model, tokenizer, text):\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(text, return_tensors='pt')\n",
    "        outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "        loss = outputs.loss\n",
    "        perplexity = torch.exp(loss).item()\n",
    "    return math.log(perplexity + 1)  # Use log scale for perplexity\n",
    "\n",
    "# Initialize conversation history\n",
    "conversation_history = []\n",
    "\n",
    "# Set up the Tkinter GUI\n",
    "root = tk.Tk()\n",
    "root.title(\"Chatbot\")\n",
    "\n",
    "# Create a scrolled text widget to display the conversation\n",
    "conversation_display = scrolledtext.ScrolledText(root, state='disabled', width=80, height=20)\n",
    "conversation_display.pack(pady=10)\n",
    "\n",
    "# Add the welcome message to the conversation display\n",
    "conversation_display.config(state='normal')\n",
    "conversation_display.insert(tk.END, \"Welcome to the Chatbot! Type 'exit' to quit.\\n\")\n",
    "conversation_display.config(state='disabled')\n",
    "conversation_display.see(tk.END)\n",
    "\n",
    "# Create an entry widget for user input\n",
    "user_input_var = tk.StringVar()\n",
    "user_input_entry = tk.Entry(root, textvariable=user_input_var, width=80)\n",
    "user_input_entry.pack(pady=10)\n",
    "user_input_entry.focus()\n",
    "\n",
    "# Function to process user input\n",
    "def process_user_input(event=None):\n",
    "    user_input = user_input_var.get()\n",
    "    if user_input.lower() in ['exit', 'quit']:\n",
    "        root.destroy()\n",
    "        return\n",
    "\n",
    "    # Clear the user input entry\n",
    "    user_input_var.set('')\n",
    "\n",
    "    # Add user input to conversation history\n",
    "    conversation_history.append(f\"User: {user_input}\")\n",
    "\n",
    "    # Update the conversation display with user input\n",
    "    conversation_display.config(state='normal')\n",
    "    conversation_display.insert(tk.END, f\"You: {user_input}\\n\")\n",
    "    conversation_display.config(state='disabled')\n",
    "    conversation_display.see(tk.END)\n",
    "\n",
    "    # Disable the user input entry while generating response\n",
    "    user_input_entry.config(state='disabled')\n",
    "\n",
    "    # Start a new thread for generating the response\n",
    "    threading.Thread(target=generate_and_display_response).start()\n",
    "\n",
    "# Function to generate and display the bot response\n",
    "def generate_and_display_response():\n",
    "    global conversation_history\n",
    "\n",
    "    # Truncate conversation history if necessary\n",
    "    conversation_history = truncate_conversation(conversation_history, max_length=1024)\n",
    "\n",
    "    # Generate bot response\n",
    "    bot_response = generate_response(conversation_history)\n",
    "\n",
    "    # Add bot response to conversation history\n",
    "    conversation_history.append(f\"Bot: {bot_response}\")\n",
    "\n",
    "    # Compute Perplexity for the bot response (log-transformed)\n",
    "    perplexity = compute_perplexity(model, tokenizer, bot_response)\n",
    "\n",
    "    # Schedule the GUI update in the main thread\n",
    "    root.after(0, update_conversation_display, bot_response, perplexity)\n",
    "\n",
    "# Function to update the conversation display in the main thread\n",
    "def update_conversation_display(bot_response, perplexity):\n",
    "    # Update the conversation display\n",
    "    conversation_display.config(state='normal')\n",
    "    conversation_display.insert(tk.END, f\"Bot: {bot_response}\\n\")\n",
    "    conversation_display.insert(tk.END, f\"Perplexity Score (log scale): {perplexity:.2f}\\n\")\n",
    "    conversation_display.insert(tk.END, \"-\" * 50 + \"\\n\")\n",
    "    conversation_display.config(state='disabled')\n",
    "    conversation_display.see(tk.END)\n",
    "\n",
    "    # Re-enable the user input entry\n",
    "    user_input_entry.config(state='normal')\n",
    "    user_input_entry.focus()\n",
    "\n",
    "# Bind the Enter key to the process_user_input function\n",
    "user_input_entry.bind(\"<Return>\", process_user_input)\n",
    "\n",
    "# Start the Tkinter main loop\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3aee44-e91e-4dce-b523-8664f1f62ff0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

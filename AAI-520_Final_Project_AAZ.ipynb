{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","authorship_tag":"ABX9TyNyV0G/0N20nAH4cDaIqUO0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"0f99ae6d59a043fea965af4950a0afcd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_798b026c5b2f42d89a815eb5f92ddfb9","IPY_MODEL_1a8479be5c4c4afa938b6d543b5460d7","IPY_MODEL_a775a63ad600448fa80d6b147ac063d1"],"layout":"IPY_MODEL_2f277f8f8b3040e99b7900e9ba58cb9e"}},"798b026c5b2f42d89a815eb5f92ddfb9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b0637100f3b43e1a7b613d0a798c87b","placeholder":"​","style":"IPY_MODEL_861cdbb6525842c98998474be28de0dc","value":"Map: 100%"}},"1a8479be5c4c4afa938b6d543b5460d7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_176dd773fdec44248003d199cab85024","max":221282,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5d1b65709249476ab9b01cbf15cee94f","value":221282}},"a775a63ad600448fa80d6b147ac063d1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c0d5147a6954aa599b485ccc7bfcef3","placeholder":"​","style":"IPY_MODEL_38826a2d4dc74facb2828833a06c4cb9","value":" 221282/221282 [01:34&lt;00:00, 2393.62 examples/s]"}},"2f277f8f8b3040e99b7900e9ba58cb9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b0637100f3b43e1a7b613d0a798c87b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"861cdbb6525842c98998474be28de0dc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"176dd773fdec44248003d199cab85024":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d1b65709249476ab9b01cbf15cee94f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2c0d5147a6954aa599b485ccc7bfcef3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38826a2d4dc74facb2828833a06c4cb9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-2ggjsaVJd9v","executionInfo":{"status":"ok","timestamp":1727032566299,"user_tz":420,"elapsed":94545,"user":{"displayName":"Aryaz Zomorodi","userId":"04002852148298941149"}},"outputId":"861d6de5-8645-49d1-d9a1-b0078195622c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Saved 221282 conversation pairs to /content/drive/My Drive/Colab Notebooks/Cornell/conversation_pairs.csv\n","Preprocessing complete! Total pairs: 221282\n"]}],"source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Set the file paths in Google Drive\n","movie_conversations_path = '/content/drive/My Drive/Colab Notebooks/Cornell/movie_conversations.txt'\n","movie_lines_path = '/content/drive/My Drive/Colab Notebooks/Cornell/movie_lines.txt'\n","\n","# Function to load the movie lines from the movie_lines.txt file\n","def load_movie_lines(movie_lines_path):\n","    lines = {}\n","    # Each line in the file has the following format: lineID +++$+++ characterID +++$+++ movieID +++$+++ character name +++$+++ text\n","    with open(movie_lines_path, encoding='utf-8', errors='ignore') as f:\n","        for line in f:\n","            parts = line.split(\" +++$+++ \")\n","            if len(parts) == 5:\n","                line_id, text = parts[0], parts[4].strip()  # lineID and actual text of the line\n","                lines[line_id] = text\n","    return lines\n","\n","# Function to load the conversation structure from the movie_conversations.txt file\n","def load_conversations(movie_conversations_path):\n","    conversations = []\n","    # Each line has the following format: characterID1 +++$+++ characterID2 +++$+++ movieID +++$+++ ['lineID1','lineID2',..., 'lineIDN']\n","    with open(movie_conversations_path, encoding='utf-8', errors='ignore') as f:\n","        for line in f:\n","            parts = line.split(\" +++$+++ \")\n","            if len(parts) == 4:\n","                line_ids_str = parts[3].strip()  # Contains the line IDs in a string format\n","                line_ids = eval(line_ids_str)  # Convert string to actual list of line IDs\n","                conversations.append(line_ids)\n","    return conversations\n","\n","# Function to create input-response pairs for chatbot training from the conversations and lines\n","def create_conversation_pairs(lines, conversations):\n","    conversation_pairs = []\n","    for conv in conversations:\n","        for i in range(len(conv) - 1):\n","            input_line = lines.get(conv[i], \"\")  # Get the input line\n","            output_line = lines.get(conv[i + 1], \"\")  # Get the response line\n","            if input_line and output_line:  # Only add pairs if both exist\n","                conversation_pairs.append((input_line, output_line))\n","    return conversation_pairs\n","\n","# Function to save conversation pairs to a CSV file\n","def save_conversation_pairs(conversation_pairs, output_path='/content/drive/My Drive/Colab Notebooks/Cornell/conversation_pairs.csv'):\n","    import pandas as pd\n","    df = pd.DataFrame(conversation_pairs, columns=['input', 'response'])\n","    df.to_csv(output_path, index=False)\n","    print(f\"Saved {len(conversation_pairs)} conversation pairs to {output_path}\")\n","\n","# Load movie lines and conversations from Google Drive\n","lines = load_movie_lines(movie_lines_path)\n","conversations = load_conversations(movie_conversations_path)\n","\n","# Create conversation pairs\n","conversation_pairs = create_conversation_pairs(lines, conversations)\n","\n","# Save the conversation pairs to a CSV file in Google Drive\n","save_conversation_pairs(conversation_pairs)\n","\n","print(f\"Preprocessing complete! Total pairs: {len(conversation_pairs)}\")\n"]},{"cell_type":"code","source":["# Install required libraries\n","!pip install transformers datasets\n","\n","# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Import necessary libraries\n","import pandas as pd\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n","from datasets import Dataset\n","\n","# Load the conversation pairs from Google Drive\n","conversation_pairs_path = '/content/drive/My Drive/Colab Notebooks/Cornell/conversation_pairs.csv'\n","conversation_df = pd.read_csv(conversation_pairs_path)\n","\n","# Preview the data\n","conversation_df.head()\n","\n","# Combine input and response into a single training format\n","def format_conversations(df):\n","    formatted_data = []\n","    for i in range(len(df)):\n","        input_text = df.loc[i, 'input']\n","        response_text = df.loc[i, 'response']\n","        # Join input and response for training as one block of conversation\n","        formatted_data.append(f\"User: {input_text}\\nBot: {response_text}\\n\")\n","    return formatted_data\n","\n","# Format the conversations for training\n","formatted_conversations = format_conversations(conversation_df)\n","\n","# Convert to Hugging Face Dataset\n","dataset = Dataset.from_dict({\"text\": formatted_conversations})\n","\n","# Load pre-trained GPT-2 model and tokenizer\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","model = GPT2LMHeadModel.from_pretrained('gpt2')\n","\n","# Add a padding token (set it to the EOS token)\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","# Tokenize the dataset and set 'labels' for loss computation\n","def tokenize_function(examples):\n","    tokenized_inputs = tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n","    # Set labels to be the same as input_ids, which GPT-2 uses for predicting the next word\n","    tokenized_inputs[\"labels\"] = tokenized_inputs[\"input_ids\"].copy()\n","    return tokenized_inputs\n","\n","tokenized_dataset = dataset.map(tokenize_function, batched=True)\n","\n","# Set up training arguments\n","training_args = TrainingArguments(\n","    output_dir=\"/content/drive/My Drive/Colab Notebooks/Cornell/gpt2-chatbot\",\n","    overwrite_output_dir=True,\n","    num_train_epochs=3,\n","    per_device_train_batch_size=16,\n","    save_steps=10_000,\n","    save_total_limit=2,\n","    logging_dir=\"/content/drive/My Drive/Colab Notebooks/Cornell/logs\",\n","    logging_steps=500,\n","    fp16=True,  # Enable mixed precision training\n",")\n","\n","# Trainer class for fine-tuning GPT-2\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_dataset,\n",")\n","\n","# Fine-tune the model\n","trainer.train()\n","\n","# Save the model to Google Drive after training\n","model.save_pretrained('/content/drive/My Drive/Colab Notebooks/Cornell/gpt2-chatbot')\n","\n","# Save the tokenizer as well\n","tokenizer.save_pretrained('/content/drive/My Drive/Colab Notebooks/Cornell/gpt2-chatbot')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["0f99ae6d59a043fea965af4950a0afcd","798b026c5b2f42d89a815eb5f92ddfb9","1a8479be5c4c4afa938b6d543b5460d7","a775a63ad600448fa80d6b147ac063d1","2f277f8f8b3040e99b7900e9ba58cb9e","9b0637100f3b43e1a7b613d0a798c87b","861cdbb6525842c98998474be28de0dc","176dd773fdec44248003d199cab85024","5d1b65709249476ab9b01cbf15cee94f","2c0d5147a6954aa599b485ccc7bfcef3","38826a2d4dc74facb2828833a06c4cb9"]},"id":"2-RSIH4jLxXr","executionInfo":{"status":"ok","timestamp":1727075156286,"user_tz":420,"elapsed":25389296,"user":{"displayName":"Aryaz Zomorodi","userId":"04002852148298941149"}},"outputId":"9a793bd4-32d5-46b1-893a-b050a75eeac0"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/221282 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f99ae6d59a043fea965af4950a0afcd"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='41493' max='41493' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [41493/41493 7:01:20, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.421000</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.213900</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.214000</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.213800</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.210500</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.210800</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.210800</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.212100</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.205900</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.207800</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>0.207700</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.208600</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>0.208400</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>0.202500</td>\n","    </tr>\n","    <tr>\n","      <td>7500</td>\n","      <td>0.206000</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>0.203700</td>\n","    </tr>\n","    <tr>\n","      <td>8500</td>\n","      <td>0.206400</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>0.202500</td>\n","    </tr>\n","    <tr>\n","      <td>9500</td>\n","      <td>0.205700</td>\n","    </tr>\n","    <tr>\n","      <td>10000</td>\n","      <td>0.205000</td>\n","    </tr>\n","    <tr>\n","      <td>10500</td>\n","      <td>0.202100</td>\n","    </tr>\n","    <tr>\n","      <td>11000</td>\n","      <td>0.201500</td>\n","    </tr>\n","    <tr>\n","      <td>11500</td>\n","      <td>0.199800</td>\n","    </tr>\n","    <tr>\n","      <td>12000</td>\n","      <td>0.202800</td>\n","    </tr>\n","    <tr>\n","      <td>12500</td>\n","      <td>0.198500</td>\n","    </tr>\n","    <tr>\n","      <td>13000</td>\n","      <td>0.197900</td>\n","    </tr>\n","    <tr>\n","      <td>13500</td>\n","      <td>0.198900</td>\n","    </tr>\n","    <tr>\n","      <td>14000</td>\n","      <td>0.199900</td>\n","    </tr>\n","    <tr>\n","      <td>14500</td>\n","      <td>0.191500</td>\n","    </tr>\n","    <tr>\n","      <td>15000</td>\n","      <td>0.194600</td>\n","    </tr>\n","    <tr>\n","      <td>15500</td>\n","      <td>0.192800</td>\n","    </tr>\n","    <tr>\n","      <td>16000</td>\n","      <td>0.196800</td>\n","    </tr>\n","    <tr>\n","      <td>16500</td>\n","      <td>0.194300</td>\n","    </tr>\n","    <tr>\n","      <td>17000</td>\n","      <td>0.194800</td>\n","    </tr>\n","    <tr>\n","      <td>17500</td>\n","      <td>0.192200</td>\n","    </tr>\n","    <tr>\n","      <td>18000</td>\n","      <td>0.191700</td>\n","    </tr>\n","    <tr>\n","      <td>18500</td>\n","      <td>0.196500</td>\n","    </tr>\n","    <tr>\n","      <td>19000</td>\n","      <td>0.194500</td>\n","    </tr>\n","    <tr>\n","      <td>19500</td>\n","      <td>0.192700</td>\n","    </tr>\n","    <tr>\n","      <td>20000</td>\n","      <td>0.193000</td>\n","    </tr>\n","    <tr>\n","      <td>20500</td>\n","      <td>0.193700</td>\n","    </tr>\n","    <tr>\n","      <td>21000</td>\n","      <td>0.192800</td>\n","    </tr>\n","    <tr>\n","      <td>21500</td>\n","      <td>0.191600</td>\n","    </tr>\n","    <tr>\n","      <td>22000</td>\n","      <td>0.194600</td>\n","    </tr>\n","    <tr>\n","      <td>22500</td>\n","      <td>0.191200</td>\n","    </tr>\n","    <tr>\n","      <td>23000</td>\n","      <td>0.193600</td>\n","    </tr>\n","    <tr>\n","      <td>23500</td>\n","      <td>0.190500</td>\n","    </tr>\n","    <tr>\n","      <td>24000</td>\n","      <td>0.194800</td>\n","    </tr>\n","    <tr>\n","      <td>24500</td>\n","      <td>0.192400</td>\n","    </tr>\n","    <tr>\n","      <td>25000</td>\n","      <td>0.192300</td>\n","    </tr>\n","    <tr>\n","      <td>25500</td>\n","      <td>0.195000</td>\n","    </tr>\n","    <tr>\n","      <td>26000</td>\n","      <td>0.192600</td>\n","    </tr>\n","    <tr>\n","      <td>26500</td>\n","      <td>0.191600</td>\n","    </tr>\n","    <tr>\n","      <td>27000</td>\n","      <td>0.192500</td>\n","    </tr>\n","    <tr>\n","      <td>27500</td>\n","      <td>0.193100</td>\n","    </tr>\n","    <tr>\n","      <td>28000</td>\n","      <td>0.187700</td>\n","    </tr>\n","    <tr>\n","      <td>28500</td>\n","      <td>0.187200</td>\n","    </tr>\n","    <tr>\n","      <td>29000</td>\n","      <td>0.186400</td>\n","    </tr>\n","    <tr>\n","      <td>29500</td>\n","      <td>0.188100</td>\n","    </tr>\n","    <tr>\n","      <td>30000</td>\n","      <td>0.188200</td>\n","    </tr>\n","    <tr>\n","      <td>30500</td>\n","      <td>0.189200</td>\n","    </tr>\n","    <tr>\n","      <td>31000</td>\n","      <td>0.186000</td>\n","    </tr>\n","    <tr>\n","      <td>31500</td>\n","      <td>0.188600</td>\n","    </tr>\n","    <tr>\n","      <td>32000</td>\n","      <td>0.187900</td>\n","    </tr>\n","    <tr>\n","      <td>32500</td>\n","      <td>0.189700</td>\n","    </tr>\n","    <tr>\n","      <td>33000</td>\n","      <td>0.186700</td>\n","    </tr>\n","    <tr>\n","      <td>33500</td>\n","      <td>0.187700</td>\n","    </tr>\n","    <tr>\n","      <td>34000</td>\n","      <td>0.186400</td>\n","    </tr>\n","    <tr>\n","      <td>34500</td>\n","      <td>0.188000</td>\n","    </tr>\n","    <tr>\n","      <td>35000</td>\n","      <td>0.188600</td>\n","    </tr>\n","    <tr>\n","      <td>35500</td>\n","      <td>0.185400</td>\n","    </tr>\n","    <tr>\n","      <td>36000</td>\n","      <td>0.184500</td>\n","    </tr>\n","    <tr>\n","      <td>36500</td>\n","      <td>0.185900</td>\n","    </tr>\n","    <tr>\n","      <td>37000</td>\n","      <td>0.187600</td>\n","    </tr>\n","    <tr>\n","      <td>37500</td>\n","      <td>0.183800</td>\n","    </tr>\n","    <tr>\n","      <td>38000</td>\n","      <td>0.186500</td>\n","    </tr>\n","    <tr>\n","      <td>38500</td>\n","      <td>0.184200</td>\n","    </tr>\n","    <tr>\n","      <td>39000</td>\n","      <td>0.184700</td>\n","    </tr>\n","    <tr>\n","      <td>39500</td>\n","      <td>0.185700</td>\n","    </tr>\n","    <tr>\n","      <td>40000</td>\n","      <td>0.187700</td>\n","    </tr>\n","    <tr>\n","      <td>40500</td>\n","      <td>0.188100</td>\n","    </tr>\n","    <tr>\n","      <td>41000</td>\n","      <td>0.187900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["('/content/drive/My Drive/Colab Notebooks/Cornell/gpt2-chatbot/tokenizer_config.json',\n"," '/content/drive/My Drive/Colab Notebooks/Cornell/gpt2-chatbot/special_tokens_map.json',\n"," '/content/drive/My Drive/Colab Notebooks/Cornell/gpt2-chatbot/vocab.json',\n"," '/content/drive/My Drive/Colab Notebooks/Cornell/gpt2-chatbot/merges.txt',\n"," '/content/drive/My Drive/Colab Notebooks/Cornell/gpt2-chatbot/added_tokens.json')"]},"metadata":{},"execution_count":4}]}]}